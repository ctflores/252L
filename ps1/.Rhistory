n <- 100 #number of needles
d <- 2 #line spacing
l <- 1 #needle length
set.seed(94305)
orient <- matrix(NA,n,4)
orient[,1] <- runif(n,0,d)
orient[,2] <- runif(n,-pi/2, pi/2)
orient[,3] <- orient[,1]+l*cos(orient[,2])
orient[,4] <- orient[,3] >= d
p <- sum(orient[,4])/n
p
n <- 10000000 #number of needles
d <- 2 #line spacing
l <- 1 #needle length
set.seed(94305)
orient <- matrix(NA,n,4)
orient[,1] <- runif(n,0,d)
orient[,2] <- runif(n,-pi/2, pi/2)
orient[,3] <- orient[,1]+l*cos(orient[,2])
orient[,4] <- orient[,3] >= d
p <- sum(orient[,4])/n
p
orient <- matrix(NA,n,4)
n <- 1000 #number of needles
d <- 1 #line spacing
l <- 1 #needle length
orient <- matrix(NA,n,4)
orient[,1] <- runif(n,0,d)
orient[,2] <- runif(n,-pi/2, pi/2)
orient[,3] <- orient[,1]+l*cos(orient[,2])
orient[,4] <- orient[,3] >= d
p <- sum(orient[,4])/n
p
install.packages(stargazer)
install.packages('stargazer')
install.packages('ggplot2')
install.packages('RColorBrewer')
install.packages('glmnet')
out<-list() #lists are really useful!! this just initializes this one so that we can use it later. read more @ http://www.r-tutor.com/r-introduction/list
##CTT item analysis
##this function will compute CTT item statistics for a generic item response matrix
item_analysis<-function(resp) { #'resp' is just a generic item response matrix, rows are people columns are items
pv<-colMeans(resp,na.rm=TRUE) #simple "p-values", which in psychometrics tends to just mean the mean number of points for an item
r.xt<-numeric() #initializing a vector
rowSums(resp,na.rm=TRUE)->ss #these are the sum scores/observed scores
for (i in 1:ncol(resp)) {
cor(ss,resp[,i],use='p')->r.xt[i]
}
cbind(pv,r.xt) #i'll return a matrix consisting of the p-values and the item/total correlations
}
resp1 <-read.table("emp-rasch.txt",header=FALSE)
out[[1]]<-item_analysis(resp1)
resp2 <-read.table("rasch.txt",header=FALSE)
out[[2]]<-item_analysis(resp2)
par(mfrow=c(2,1),mgp=c(2,1,0),mar=c(3,3,1,1))
plot(out[[1]])
plot(out[[2]])
par(mfrow=c(2,2),mgp=c(2,1,0),mar=c(3,3,1,1))
pf<-function(x) {
plot(density(x[,1]),xlim=c(0,1),xlab="density, p-values")
plot(density(x[,2]),xlim=c(0,1),xlab="density, item-total correlations")
}
lapply(out,pf)
hist(colSums(x1))
#################################################
##Exploration of collections of bernoulli variables
#################################################
set.seed(12311)
x1<-matrix(rbinom(1000,1,.5),100,10)
##Q. Compute all the correlations of the columns of this matrix (x1). What do you notice?
##A. The matrix has 1's along the diagonal (variables correlate perfectly with themselves) and the matrix is symmetric about the diagonal [cor(x,y) = cor(y,x)]
cor(x1)
##Q. Compute the row sums. What is the variation in row sums?
##A. 2.706667 - Given the context of the following question, this represents variance in total test scores.
var(rowSums(x1))
##Q. If you considered the 1s/0s correct and incorrect responses to test items (where the rows are people and the columns are items), does this seem like it could have come from a realistic scenario?
##A. Probably not, but it depends on what the test looked like (is it super random general knowledge type questions?).  One might expect a test to have "easy" and "hard" questions, which this randomly constructed matrix does not indicate.
#################################################
##Feel free to ignore this bit. I'm going to generate a new set of data.
set.seed(12311)
th<-matrix(rnorm(100),100,10,byrow=FALSE)
diff<-matrix<-matrix(rnorm(10),100,10,byrow=TRUE)
kern<- exp(th - diff)
pr<-kern/(1+kern)
test<-matrix(runif(1000),100,10)
x2<-ifelse(pr>test,1,0)
##Q. Now go back through the above questions and see what you make of this new matrix x2. Specifically, how does it compare to the first matrix x1 in terms of whether it seems like a realistic set of item responses? What characteristics (feel free to explore other features of the data) influence your opinion on this point?
##A. Looking at histograms of row sums in x1 and x2, x2 is less clearly normally distributed - meaning that there are respondants at lower ability levels, but a sharper drop off after 7 (and 8) correct.  More than anything, the difference in the variance between the column sums (61.7 in x and 242.7 in x2) implies that all the items in x1 would have been of similar difficulty, whereas the items in x2 are of varying difficulty.  In practice, it's hard to write items that are of similar difficulty and have respondants of similar scores have wildly different response profiles.
##Q. Compute all the correlations of the columns of this matrix (x1). What do you notice?
##A. Same as above.
cor(x2)
##Q. Compute the row sums. What is the variation in row sums?
##A. 5.111111 - The variation in row sums here is higher.  The data is also somewhat more uniformly distributed than in x1, so it makes sense that the variance would be higher in this situation.
rowSums(x2)
var(rowSums(x2))
##Q. If you considered the 1s/0s correct and incorrect responses to test items (where the rows are people and the columns are items), does this seem like it could have come from a realistic scenario?
##A.  Considering the column sums, it's clear that there are items that are more difficult (20 correct responses) and less difficult (69 or 73 correct responses), so in this sense, it is somewhat more realistic.
hist(colSums(x1))
#################################################
##Exploration of collections of bernoulli variables
#################################################
set.seed(12311)
x1<-matrix(rbinom(1000,1,.5),100,10)
##Q. Compute all the correlations of the columns of this matrix (x1). What do you notice?
##A. The matrix has 1's along the diagonal (variables correlate perfectly with themselves) and the matrix is symmetric about the diagonal [cor(x,y) = cor(y,x)]
cor(x1)
##Q. Compute the row sums. What is the variation in row sums?
##A. 2.706667 - Given the context of the following question, this represents variance in total test scores.
var(rowSums(x1))
##Q. If you considered the 1s/0s correct and incorrect responses to test items (where the rows are people and the columns are items), does this seem like it could have come from a realistic scenario?
##A. Probably not, but it depends on what the test looked like (is it super random general knowledge type questions?).  One might expect a test to have "easy" and "hard" questions, which this randomly constructed matrix does not indicate.
#################################################
##Feel free to ignore this bit. I'm going to generate a new set of data.
set.seed(12311)
th<-matrix(rnorm(100),100,10,byrow=FALSE)
diff<-matrix<-matrix(rnorm(10),100,10,byrow=TRUE)
kern<- exp(th - diff)
pr<-kern/(1+kern)
test<-matrix(runif(1000),100,10)
x2<-ifelse(pr>test,1,0)
##Q. Now go back through the above questions and see what you make of this new matrix x2. Specifically, how does it compare to the first matrix x1 in terms of whether it seems like a realistic set of item responses? What characteristics (feel free to explore other features of the data) influence your opinion on this point?
##A. Looking at histograms of row sums in x1 and x2, x2 is less clearly normally distributed - meaning that there are respondants at lower ability levels, but a sharper drop off after 7 (and 8) correct.  More than anything, the difference in the variance between the column sums (61.7 in x and 242.7 in x2) implies that all the items in x1 would have been of similar difficulty, whereas the items in x2 are of varying difficulty.  In practice, it's hard to write items that are of similar difficulty and have respondants of similar scores have wildly different response profiles.
##Q. Compute all the correlations of the columns of this matrix (x1). What do you notice?
##A. Same as above.
cor(x2)
##Q. Compute the row sums. What is the variation in row sums?
##A. 5.111111 - The variation in row sums here is higher.  The data is also somewhat more uniformly distributed than in x1, so it makes sense that the variance would be higher in this situation.
rowSums(x2)
var(rowSums(x2))
##Q. If you considered the 1s/0s correct and incorrect responses to test items (where the rows are people and the columns are items), does this seem like it could have come from a realistic scenario?
##A.  Considering the column sums, it's clear that there are items that are more difficult (20 correct responses) and less difficult (69 or 73 correct responses), so in this sense, it is somewhat more realistic.
hist(colSums(x1))
hist(colSums(x2))
#################################################
##Exploration of collections of bernoulli variables
#################################################
set.seed(12311)
x1<-matrix(rbinom(1000,1,.5),100,10)
##Q. Compute all the correlations of the columns of this matrix (x1). What do you notice?
##A. The matrix has 1's along the diagonal (variables correlate perfectly with themselves) and the matrix is symmetric about the diagonal [cor(x,y) = cor(y,x)]
cor(x1)
##Q. Compute the row sums. What is the variation in row sums?
##A. 2.706667 - Given the context of the following question, this represents variance in total test scores.
var(rowSums(x1))
##Q. If you considered the 1s/0s correct and incorrect responses to test items (where the rows are people and the columns are items), does this seem like it could have come from a realistic scenario?
##A. Probably not, but it depends on what the test looked like (is it super random general knowledge type questions?).  One might expect a test to have "easy" and "hard" questions, which this randomly constructed matrix does not indicate.
#################################################
##Feel free to ignore this bit. I'm going to generate a new set of data.
set.seed(12311)
th<-matrix(rnorm(100),100,10,byrow=FALSE)
diff<-matrix<-matrix(rnorm(10),100,10,byrow=TRUE)
kern<- exp(th - diff)
pr<-kern/(1+kern)
test<-matrix(runif(1000),100,10)
x2<-ifelse(pr>test,1,0)
##Q. Now go back through the above questions and see what you make of this new matrix x2. Specifically, how does it compare to the first matrix x1 in terms of whether it seems like a realistic set of item responses? What characteristics (feel free to explore other features of the data) influence your opinion on this point?
##A. Looking at histograms of row sums in x1 and x2, x2 is less clearly normally distributed - meaning that there are respondants at lower ability levels, but a sharper drop off after 7 (and 8) correct.  More than anything, the difference in the variance between the column sums (61.7 in x and 242.7 in x2) implies that all the items in x1 would have been of similar difficulty, whereas the items in x2 are of varying difficulty.  In practice, it's hard to write items that are of similar difficulty and have respondants of similar scores have wildly different response profiles.
##Q. Compute all the correlations of the columns of this matrix (x1). What do you notice?
##A. Same as above.
cor(x2)
##Q. Compute the row sums. What is the variation in row sums?
##A. 5.111111 - The variation in row sums here is higher.  The data is also somewhat more uniformly distributed than in x1, so it makes sense that the variance would be higher in this situation.
rowSums(x2)
var(rowSums(x2))
##Q. If you considered the 1s/0s correct and incorrect responses to test items (where the rows are people and the columns are items), does this seem like it could have come from a realistic scenario?
##A.  Considering the column sums, it's clear that there are items that are more difficult (20 correct responses) and less difficult (69 or 73 correct responses), so in this sense, it is somewhat more realistic.
var(colSums(x1))
var(colSums(x2))
hist(colSums(x1))
hist(colSums(x2))
load("ps1-logreg.Rdata")
glm(y1~x,df,family="binomial")->m1
glm(y2~x,df,family="binomial")->m2
par(mfrow=c(1,2))
plot(density(m1$resid))
plot(density(m2$resid)) ##m2 was actually simulated to have a lower asymptote such that one never had less than pr(1)=0.2, hence the asymmetry.
